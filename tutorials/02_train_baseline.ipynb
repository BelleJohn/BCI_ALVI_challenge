{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Baseline\n",
    "\n",
    "This notebook shows how to train the baseline model for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from utils.train import TrainConfig, run_train_model\n",
    "from utils.augmentations import get_default_transform\n",
    "from utils import creating_dataset\n",
    "\n",
    "# this is the implementation of the custom baseline model\n",
    "from utils import hvatnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trainer configuration\n",
    "\n",
    "The `TrainConfig` class is used to train the baseline model - have a look at the parameters it has!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(exp_name='test_2_run_fedya', p_augs=0.3, batch_size=64, eval_interval=150, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = r\"F:\\Dropbox (Personal)\\BCII\\BCI Challenges\\2024 ALVI EMG Decoding\\dataset_v2_blocks\\dataset_v2_blocks\"\n",
    "DATA_PATH = \"/media/lutetia/Extreme SSD/EMG_Yun/bci-initiative-alvi-hci-challenge/dataset_v2_blocks/dataset_v2_blocks\"\n",
    "\n",
    "def count_parameters(model): \n",
    "    n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    n_total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total: {n_total/1e6:.2f}M, Trainable: {n_trainable/1e6:.2f}M\")\n",
    "    return n_total, n_trainable\n",
    "\n",
    "\n",
    "    \n",
    "## Data preparation\n",
    "transform = get_default_transform(train_config.p_augs)\n",
    "data_paths = dict(datasets=[DATA_PATH],\n",
    "                    hand_type = ['left', 'right'], # [left, 'right']\n",
    "                    human_type = ['health', 'amputant'], # [amputant, 'health']\n",
    "                    test_dataset_list = ['fedya_tropin_standart_elbow_left'])\n",
    "data_config = creating_dataset.DataConfig(**data_paths)\n",
    "train_dataset, test_dataset = creating_dataset.get_datasets(data_config, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "As you can see below, the model has a number of hyperparameters specifying its architecture and parameters. These are the parameters used to generate the baseline predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = hvatnet.Config(n_electrodes=8, n_channels_out=20,\n",
    "                            n_res_blocks=3, n_blocks_per_layer=3,\n",
    "                            n_filters=128, kernel_size=3, \n",
    "                            strides=(2, 2, 2), dilation=2, \n",
    "                            small_strides = (2, 2))\n",
    "model = hvatnet.HVATNetv3(model_config)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the predictions are downsampled at 25Hz from the data originally recorded at 200Hz. The `hvatnet` model used here, automatically and correctly downsamples the data during predictions. Make sure that your model's oputput is also downsampled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "Y_hat = model(torch.tensor(X).unsqueeze(0)).squeeze().detach().numpy()\n",
    "\n",
    "print(f\"Predictions shape: {Y_hat.shape}\")\n",
    "\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains the baseline model using training code defined in `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter1d, gaussian_filter1d\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Post-processing functions\n",
    "def moving_average(data, window_size, axis=0):\n",
    "    return uniform_filter1d(data, size=window_size, axis=axis, mode='reflect')\n",
    "\n",
    "def savitzky_golay_filter(data, window_size, poly_order, axis=0):\n",
    "    return savgol_filter(data, window_size, poly_order, axis=axis)\n",
    "\n",
    "def gaussian_smoothing(data, sigma, axis=0):\n",
    "    return gaussian_filter1d(data, sigma, axis=axis)\n",
    "\n",
    "def example_post_process(data):\n",
    "    return None\n",
    "    # return moving_average(data, window_size=3,axis=-1) # window_size=3-15\n",
    "    # return savitzky_golay_filter(data, window_size=3, poly_order=2) #window_size=3-15, poly_order=2-5\n",
    "    # return gaussian_smoothing(data, sigma=1) #sigma=0.1-2\n",
    "\n",
    "\n",
    "run_train_model(model, (train_dataset, test_dataset), train_config, device) #post_process=example_post_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
