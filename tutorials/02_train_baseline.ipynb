{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Baseline\n",
    "\n",
    "This notebook shows how to train the baseline model for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from utils.train import TrainConfig, run_train_model\n",
    "from utils.augmentations import get_default_transform\n",
    "from utils import creating_dataset\n",
    "\n",
    "# this is the implementation of the custom baseline model\n",
    "from utils import hvatnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define trainer configuration\n",
    "\n",
    "The `TrainConfig` class is used to train the baseline model - have a look at the parameters it has!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(exp_name='test_2_run_fedya', p_augs=0.3, batch_size=64, eval_interval=150, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting val datasets\n",
      "Number of moves: 72 | Dataset: fedya_tropin_standart_elbow_left\n",
      "Reorder this dataset fedya_tropin_standart_elbow_left True\n",
      "Getting train datasets\n",
      "Number of moves: 72 | Dataset: fedya_tropin_standart_elbow_left\n",
      "Reorder this dataset fedya_tropin_standart_elbow_left True\n",
      "Number of moves: 70 | Dataset: valery_first_standart_elbow_left\n",
      "Reorder this dataset valery_first_standart_elbow_left True\n",
      "Number of moves: 135 | Dataset: alex_kovalev_standart_elbow_left\n",
      "Reorder this dataset alex_kovalev_standart_elbow_left True\n",
      "Number of moves: 72 | Dataset: anna_makarova_standart_elbow_left\n",
      "Reorder this dataset anna_makarova_standart_elbow_left True\n",
      "Number of moves: 62 | Dataset: artem_snailbox_standart_elbow_left\n",
      "Reorder this dataset artem_snailbox_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: matthew_antonov_standart_elbow_left\n",
      "Reorder this dataset matthew_antonov_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: misha_korobok_standart_elbow_left\n",
      "Reorder this dataset misha_korobok_standart_elbow_left True\n",
      "Number of moves: 71 | Dataset: nikita_snailbox_standart_elbow_left\n",
      "Reorder this dataset nikita_snailbox_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: petya_chizhov_standart_elbow_left\n",
      "Reorder this dataset petya_chizhov_standart_elbow_left True\n",
      "Number of moves: 12 | Dataset: polina_maksimova_standart_elbow_left\n",
      "Reorder this dataset polina_maksimova_standart_elbow_left True\n",
      "Number of moves: 144 | Dataset: sema_duplin_standart_elbow_left\n",
      "Reorder this dataset sema_duplin_standart_elbow_left True\n",
      "Number of moves: 136 | Dataset: alex_kovalev_standart_elbow_right\n",
      "Number of moves: 69 | Dataset: andrew_snailbox_standart_elbow_right\n",
      "Number of moves: 132 | Dataset: anna_makarova_standart_elbow_right\n",
      "Number of moves: 67 | Dataset: artem_snailbox_standart_elbow_right\n",
      "Number of moves: 68 | Dataset: matthew_antonov_standart_elbow_right\n",
      "Number of moves: 72 | Dataset: matvey_gorbenko_standart_elbow_right\n",
      "Number of moves: 144 | Dataset: misha_korobok_standart_elbow_right\n",
      "Number of moves: 55 | Dataset: nikita_snailbox_standart_elbow_right\n",
      "Number of moves: 142 | Dataset: petya_chizhov_standart_elbow_right\n",
      "Number of moves: 54 | Dataset: polina_maksimova_standart_elbow_right\n",
      "Number of moves: 139 | Dataset: sema_duplin_standart_elbow_right\n",
      "Number of trainining sessions: 22\n",
      "Number of validation sessions: 1\n",
      "Size of the input (8, 256) || Size of the output (20, 32)\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = r\"F:\\Dropbox (Personal)\\BCII\\BCI Challenges\\2024 ALVI EMG Decoding\\dataset_v2_blocks\\dataset_v2_blocks\"\n",
    "DATA_PATH = \"/media/lutetia/Extreme SSD/EMG_Yun/bci-initiative-alvi-hci-challenge/dataset_v2_blocks/dataset_v2_blocks\"\n",
    "\n",
    "def count_parameters(model): \n",
    "    n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    n_total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total: {n_total/1e6:.2f}M, Trainable: {n_trainable/1e6:.2f}M\")\n",
    "    return n_total, n_trainable\n",
    "\n",
    "\n",
    "    \n",
    "## Data preparation\n",
    "transform = get_default_transform(train_config.p_augs)\n",
    "data_paths = dict(datasets=[DATA_PATH],\n",
    "                    hand_type = ['left', 'right'], # [left, 'right']\n",
    "                    human_type = ['health', 'amputant'], # [amputant, 'health']\n",
    "                    test_dataset_list = ['fedya_tropin_standart_elbow_left'])\n",
    "data_config = creating_dataset.DataConfig(**data_paths)\n",
    "train_dataset, test_dataset = creating_dataset.get_datasets(data_config, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "As you can see below, the model has a number of hyperparameters specifying its architecture and parameters. These are the parameters used to generate the baseline predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4210788\n",
      "Total: 4.23M, Trainable: 4.23M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4231429, 4231429)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = hvatnet.Config(n_electrodes=8, n_channels_out=20,\n",
    "                            n_res_blocks=3, n_blocks_per_layer=3,\n",
    "                            n_filters=128, kernel_size=3,\n",
    "                            strides=(2, 2, 2), dilation=2, \n",
    "                            small_strides = (2, 2))\n",
    "model = hvatnet.HVATNetv3(model_config)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the predictions are downsampled at 25Hz from the data originally recorded at 200Hz. The `hvatnet` model used here, automatically and correctly downsamples the data during predictions. Make sure that your model's oputput is also downsampled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8, 256), Y shape: (20, 32)\n",
      "Predictions shape: (20, 32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "Y_hat = model(torch.tensor(X).unsqueeze(0)).squeeze().detach().numpy()\n",
    "\n",
    "print(f\"Predictions shape: {Y_hat.shape}\")\n",
    "\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code trains the baseline model using training code defined in `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed initialization of scheduler\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 150: 0.18349376320838928\n",
      "val loss: 0.1840226948261261\n",
      "saved model:  step_150_loss_0.1840.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 300: 0.15588481724262238\n",
      "val loss: 0.1777040958404541\n",
      "saved model:  step_300_loss_0.1777.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 450: 0.16865788400173187\n",
      "val loss: 0.2012651115655899\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 600: 0.12270639091730118\n",
      "val loss: 0.19821985065937042\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 750: 0.13492439687252045\n",
      "val loss: 0.19759507477283478\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 900: 0.11686334758996964\n",
      "val loss: 0.19013214111328125\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1050: 0.13579249382019043\n",
      "val loss: 0.20482949912548065\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1200: 0.13843223452568054\n",
      "val loss: 0.1580595225095749\n",
      "saved model:  step_1200_loss_0.1581.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1350: 0.13165593147277832\n",
      "val loss: 0.1730833351612091\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1500: 0.15247604250907898\n",
      "val loss: 0.16085980832576752\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1650: 0.12453428655862808\n",
      "val loss: 0.19399148225784302\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1800: 0.1273079365491867\n",
      "val loss: 0.1568962186574936\n",
      "saved model:  step_1800_loss_0.1569.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 1950: 0.11540158092975616\n",
      "val loss: 0.15312114357948303\n",
      "saved model:  step_1950_loss_0.1531.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2100: 0.15508821606636047\n",
      "val loss: 0.15055087208747864\n",
      "saved model:  step_2100_loss_0.1506.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2250: 0.15043102204799652\n",
      "val loss: 0.1653415709733963\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2400: 0.14183710515499115\n",
      "val loss: 0.15821340680122375\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2550: 0.10820354521274567\n",
      "val loss: 0.14705006778240204\n",
      "saved model:  step_2550_loss_0.1471.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2700: 0.12627147138118744\n",
      "val loss: 0.15200740098953247\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 2850: 0.11788360029459\n",
      "val loss: 0.15082816779613495\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3000: 0.14122901856899261\n",
      "val loss: 0.1579926311969757\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3150: 0.12520912289619446\n",
      "val loss: 0.14159083366394043\n",
      "saved model:  step_3150_loss_0.1416.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3300: 0.11251499503850937\n",
      "val loss: 0.15999117493629456\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3450: 0.13696101307868958\n",
      "val loss: 0.15562944114208221\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3600: 0.13603194057941437\n",
      "val loss: 0.166134312748909\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3750: 0.12649419903755188\n",
      "val loss: 0.14232824742794037\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 3900: 0.12078025192022324\n",
      "val loss: 0.1425262838602066\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4050: 0.11304265260696411\n",
      "val loss: 0.1786252111196518\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4200: 0.12934653460979462\n",
      "val loss: 0.14844734966754913\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4350: 0.1375361531972885\n",
      "val loss: 0.16142164170742035\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4500: 0.12547318637371063\n",
      "val loss: 0.14863108098506927\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4650: 0.1204003319144249\n",
      "val loss: 0.14847826957702637\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4800: 0.10566812008619308\n",
      "val loss: 0.16129587590694427\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 4950: 0.16107754409313202\n",
      "val loss: 0.14726895093917847\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5100: 0.12755762040615082\n",
      "val loss: 0.14996913075447083\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5250: 0.13961167633533478\n",
      "val loss: 0.16794364154338837\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5400: 0.11153309792280197\n",
      "val loss: 0.1557304859161377\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5550: 0.0905127301812172\n",
      "val loss: 0.1470368355512619\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5700: 0.10225435346364975\n",
      "val loss: 0.15404000878334045\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 5850: 0.10938110202550888\n",
      "val loss: 0.17360681295394897\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6000: 0.12601161003112793\n",
      "val loss: 0.14830125868320465\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6150: 0.11566799134016037\n",
      "val loss: 0.15693217515945435\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6300: 0.11050386726856232\n",
      "val loss: 0.15709494054317474\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6450: 0.10897789150476456\n",
      "val loss: 0.15141324698925018\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6600: 0.10127440840005875\n",
      "val loss: 0.15710566937923431\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6750: 0.13567428290843964\n",
      "val loss: 0.13697326183319092\n",
      "saved model:  step_6750_loss_0.1370.safetensors\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 6900: 0.14032703638076782\n",
      "val loss: 0.1529408097267151\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7050: 0.12893076241016388\n",
      "val loss: 0.15814855694770813\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7200: 0.13191376626491547\n",
      "val loss: 0.17100544273853302\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7350: 0.12170933932065964\n",
      "val loss: 0.15868186950683594\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7500: 0.1389589160680771\n",
      "val loss: 0.15807488560676575\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7650: 0.2661624848842621\n",
      "val loss: 0.18852469325065613\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7800: 0.18920809030532837\n",
      "val loss: 0.18286457657814026\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 7950: 0.14514021575450897\n",
      "val loss: 0.17618012428283691\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8100: 0.18367096781730652\n",
      "val loss: 0.19993741810321808\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8250: 0.1691870242357254\n",
      "val loss: 0.21546654403209686\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8400: 0.16589175164699554\n",
      "val loss: 0.17693324387073517\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8550: 0.16244423389434814\n",
      "val loss: 0.16601000726222992\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8700: 0.17020849883556366\n",
      "val loss: 0.19072476029396057\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 8850: 0.14154492318630219\n",
      "val loss: 0.18053051829338074\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9000: 0.15704992413520813\n",
      "val loss: 0.17403973639011383\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9150: 0.15750478208065033\n",
      "val loss: 0.17487864196300507\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9300: 0.14207696914672852\n",
      "val loss: 0.20193754136562347\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9450: 0.13851496577262878\n",
      "val loss: 0.1779775619506836\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9600: 0.16443847119808197\n",
      "val loss: 0.20711615681648254\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9750: 0.15369343757629395\n",
      "val loss: 0.21322566270828247\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 9900: 0.2105952799320221\n",
      "val loss: 0.1859356313943863\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10050: 0.1476851999759674\n",
      "val loss: 0.20156711339950562\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10200: 0.1755448281764984\n",
      "val loss: 0.17975948750972748\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10350: 0.16087572276592255\n",
      "val loss: 0.26085931062698364\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10500: 0.13764514029026031\n",
      "val loss: 0.19778145849704742\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10650: 0.18668590486049652\n",
      "val loss: 0.18199235200881958\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10800: 0.1748122125864029\n",
      "val loss: 0.1720268726348877\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 10950: 0.16307108104228973\n",
      "val loss: 0.18067213892936707\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11100: 0.14543461799621582\n",
      "val loss: 0.19076299667358398\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11250: 0.16433854401111603\n",
      "val loss: 0.19998334348201752\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11400: 0.15986725687980652\n",
      "val loss: 0.23242317140102386\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11550: 0.17622797191143036\n",
      "val loss: 0.19402801990509033\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11700: 0.1888948678970337\n",
      "val loss: 0.20045055449008942\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 11850: 0.14245350658893585\n",
      "val loss: 0.1815376728773117\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12000: 0.17115388810634613\n",
      "val loss: 0.19783754646778107\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12150: 0.18965213000774384\n",
      "val loss: 0.17890074849128723\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12300: 0.16628822684288025\n",
      "val loss: 0.1811218559741974\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12450: 0.20131786167621613\n",
      "val loss: 0.20326264202594757\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12600: 0.14981010556221008\n",
      "val loss: 0.20772548019886017\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12750: 0.18879972398281097\n",
      "val loss: 0.20585869252681732\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 12900: 0.17125597596168518\n",
      "val loss: 0.1776236891746521\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13050: 0.1910485327243805\n",
      "val loss: 0.18310493230819702\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13200: 0.1993647962808609\n",
      "val loss: 0.22109395265579224\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13350: 0.15837979316711426\n",
      "val loss: 0.17114725708961487\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13500: 0.19988034665584564\n",
      "val loss: 0.19580590724945068\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13650: 0.3345497250556946\n",
      "val loss: 0.2075335532426834\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13800: 0.22969570755958557\n",
      "val loss: 0.20531335473060608\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 13950: 0.17013046145439148\n",
      "val loss: 0.17495842278003693\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14100: 0.17587366700172424\n",
      "val loss: 0.1901179403066635\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14250: 0.17407214641571045\n",
      "val loss: 0.17682978510856628\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14400: 0.17598998546600342\n",
      "val loss: 0.1984749585390091\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14550: 0.17717857658863068\n",
      "val loss: 0.22347582876682281\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14700: 0.17076389491558075\n",
      "val loss: 0.20008249580860138\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 14850: 0.19557544589042664\n",
      "val loss: 0.16463616490364075\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15000: 0.219940185546875\n",
      "val loss: 0.17530526220798492\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15150: 0.16478076577186584\n",
      "val loss: 0.25143399834632874\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15300: 0.2113991528749466\n",
      "val loss: 0.201277956366539\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15450: 0.18609920144081116\n",
      "val loss: 0.20267561078071594\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15600: 0.1788412630558014\n",
      "val loss: 0.21826475858688354\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15750: 0.17479710280895233\n",
      "val loss: 0.17339901626110077\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 15900: 0.21867132186889648\n",
      "val loss: 0.17115424573421478\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16050: 0.22431817650794983\n",
      "val loss: 0.23502202332019806\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16200: 0.18731556832790375\n",
      "val loss: 0.17201852798461914\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16350: 0.1784542351961136\n",
      "val loss: 0.17065823078155518\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16500: 0.17746084928512573\n",
      "val loss: 0.17957670986652374\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16650: 0.17308063805103302\n",
      "val loss: 0.17900680005550385\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16800: 0.20456258952617645\n",
      "val loss: 0.1940697580575943\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 16950: 0.1711856871843338\n",
      "val loss: 0.2257014513015747\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17100: 0.16620202362537384\n",
      "val loss: 0.17593316733837128\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17250: 0.1675519496202469\n",
      "val loss: 0.1813674420118332\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17400: 0.1877400428056717\n",
      "val loss: 0.1827642023563385\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17550: 0.16032399237155914\n",
      "val loss: 0.17825113236904144\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17700: 0.16504906117916107\n",
      "val loss: 0.18575376272201538\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 17850: 0.2024228870868683\n",
      "val loss: 0.18753914535045624\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18000: 0.2021419256925583\n",
      "val loss: 0.1823924332857132\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18150: 0.19119708240032196\n",
      "val loss: 0.19205120205879211\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18300: 0.18443241715431213\n",
      "val loss: 0.17883814871311188\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18450: 0.18174561858177185\n",
      "val loss: 0.19185060262680054\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18600: 0.19533221423625946\n",
      "val loss: 0.1879996955394745\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18750: 0.212314173579216\n",
      "val loss: 0.17765392363071442\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 18900: 0.21875861287117004\n",
      "val loss: 0.18140193819999695\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19050: 0.1721561700105667\n",
      "val loss: 0.16945615410804749\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19200: 0.20372188091278076\n",
      "val loss: 0.19333893060684204\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19350: 0.16343556344509125\n",
      "val loss: 0.18428774178028107\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19500: 0.18506167829036713\n",
      "val loss: 0.1709531843662262\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19650: 0.2192150205373764\n",
      "val loss: 0.19091571867465973\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19800: 0.21410112082958221\n",
      "val loss: 0.22274252772331238\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 19950: 0.19164717197418213\n",
      "val loss: 0.17304742336273193\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20100: 0.2107187807559967\n",
      "val loss: 0.1732720285654068\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20250: 0.1964593231678009\n",
      "val loss: 0.17593292891979218\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20400: 0.2138155698776245\n",
      "val loss: 0.1799386739730835\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20550: 0.29567885398864746\n",
      "val loss: 0.3198494613170624\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20700: 0.19145791232585907\n",
      "val loss: 0.1692291647195816\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 20850: 0.18022553622722626\n",
      "val loss: 0.168229877948761\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21000: 0.1771053820848465\n",
      "val loss: 0.17178089916706085\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21150: 0.16892491281032562\n",
      "val loss: 0.1763281226158142\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21300: 0.20137794315814972\n",
      "val loss: 0.1740046739578247\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21450: 0.1973721981048584\n",
      "val loss: 0.16780780255794525\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21600: 0.1848752647638321\n",
      "val loss: 0.17719514667987823\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21750: 0.20411475002765656\n",
      "val loss: 0.18761855363845825\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 21900: 0.30058786273002625\n",
      "val loss: 0.2204897701740265\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22050: 0.17226244509220123\n",
      "val loss: 0.18380704522132874\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22200: 0.21985271573066711\n",
      "val loss: 0.17762428522109985\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22350: 0.18603818118572235\n",
      "val loss: 0.1739770472049713\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22500: 0.2229735106229782\n",
      "val loss: 0.17485733330249786\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22650: 0.20331358909606934\n",
      "val loss: 0.16916631162166595\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22800: 0.2221132069826126\n",
      "val loss: 0.18054896593093872\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 22950: 0.21550165116786957\n",
      "val loss: 0.18156008422374725\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23100: 0.196628600358963\n",
      "val loss: 0.17758755385875702\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23250: 0.18387944996356964\n",
      "val loss: 0.18332169950008392\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23400: 0.18445897102355957\n",
      "val loss: 0.1765974909067154\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23550: 0.21199603378772736\n",
      "val loss: 0.18775856494903564\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23700: 0.16578097641468048\n",
      "val loss: 0.19003745913505554\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 23850: 0.15482833981513977\n",
      "val loss: 0.18012498319149017\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24000: 0.35947346687316895\n",
      "val loss: 0.2693621516227722\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24150: 0.20658265054225922\n",
      "val loss: 0.1934228539466858\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24300: 0.19186782836914062\n",
      "val loss: 0.1758996546268463\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24450: 0.19505932927131653\n",
      "val loss: 0.17987728118896484\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24600: 0.16272416710853577\n",
      "val loss: 0.17086249589920044\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24750: 0.1767999529838562\n",
      "val loss: 0.17625083029270172\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 24900: 0.21965084969997406\n",
      "val loss: 0.18610845506191254\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25050: 0.21706806123256683\n",
      "val loss: 0.1808985322713852\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25200: 0.19743159413337708\n",
      "val loss: 0.17749075591564178\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25350: 0.21748743951320648\n",
      "val loss: 0.1746000200510025\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25500: 0.21783387660980225\n",
      "val loss: 0.17928548157215118\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25650: 0.19984473288059235\n",
      "val loss: 0.17795009911060333\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25800: 0.20668485760688782\n",
      "val loss: 0.17485050857067108\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 25950: 0.2427639216184616\n",
      "val loss: 0.17591719329357147\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26100: 0.21879711747169495\n",
      "val loss: 0.221037358045578\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26250: 0.23989219963550568\n",
      "val loss: 0.192310631275177\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26400: 0.26961952447891235\n",
      "val loss: 0.23210664093494415\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26550: 0.3324829638004303\n",
      "val loss: 0.36837154626846313\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26700: 0.20047521591186523\n",
      "val loss: 0.20232616364955902\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 26850: 0.2090575248003006\n",
      "val loss: 0.30550462007522583\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27000: 0.19539307057857513\n",
      "val loss: 0.18541064858436584\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27150: 0.22288012504577637\n",
      "val loss: 0.17799519002437592\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27300: 0.19847939908504486\n",
      "val loss: 0.20275281369686127\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27450: 0.2012130469083786\n",
      "val loss: 0.1804766207933426\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27600: 0.2039254754781723\n",
      "val loss: 0.192729189991951\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27750: 0.21606290340423584\n",
      "val loss: 0.18461279571056366\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 27900: 0.19724245369434357\n",
      "val loss: 0.18517619371414185\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28050: 0.19660013914108276\n",
      "val loss: 0.18278712034225464\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28200: 0.2068411409854889\n",
      "val loss: 0.18087035417556763\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28350: 0.19806413352489471\n",
      "val loss: 0.1795075684785843\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28500: 0.19815130531787872\n",
      "val loss: 0.18343570828437805\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28650: 0.21444879472255707\n",
      "val loss: 0.1940649300813675\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28800: 0.19457295536994934\n",
      "val loss: 0.17975910007953644\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 28950: 0.2180013507604599\n",
      "val loss: 0.18443907797336578\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29100: 0.23667602241039276\n",
      "val loss: 0.18401820957660675\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29250: 0.20226441323757172\n",
      "val loss: 0.18193495273590088\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29400: 0.21479296684265137\n",
      "val loss: 0.18225109577178955\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29550: 0.2794972360134125\n",
      "val loss: 0.18598073720932007\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29700: 0.24538622796535492\n",
      "val loss: 0.18825943768024445\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 29850: 0.28449779748916626\n",
      "val loss: 0.19027288258075714\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30000: 0.23791217803955078\n",
      "val loss: 0.18393714725971222\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30150: 0.22036169469356537\n",
      "val loss: 0.18222546577453613\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30300: 0.19920222461223602\n",
      "val loss: 0.18237340450286865\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30450: 0.25629112124443054\n",
      "val loss: 0.18521833419799805\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30600: 0.23044143617153168\n",
      "val loss: 0.18412359058856964\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30750: 0.21607445180416107\n",
      "val loss: 0.1823984682559967\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 30900: 0.3164888322353363\n",
      "val loss: 0.1933223307132721\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31050: 0.23436594009399414\n",
      "val loss: 0.18905360996723175\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31200: 0.2323661595582962\n",
      "val loss: 0.18582604825496674\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31350: 0.19408729672431946\n",
      "val loss: 0.18920020759105682\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31500: 0.21210666000843048\n",
      "val loss: 0.20599864423274994\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31650: 0.19825796782970428\n",
      "val loss: 0.19478100538253784\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31800: 0.23336069285869598\n",
      "val loss: 0.18393290042877197\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 31950: 0.19634060561656952\n",
      "val loss: 0.19452133774757385\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32100: 0.23294375836849213\n",
      "val loss: 0.19021040201187134\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32250: 0.20304976403713226\n",
      "val loss: 0.1822521686553955\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32400: 0.19139361381530762\n",
      "val loss: 0.18075565993785858\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32550: 0.1696886569261551\n",
      "val loss: 0.1834738850593567\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32700: 0.20012521743774414\n",
      "val loss: 0.19144296646118164\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 32850: 0.1799921989440918\n",
      "val loss: 0.18096968531608582\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33000: 0.2048109769821167\n",
      "val loss: 0.18101000785827637\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33150: 0.24437947571277618\n",
      "val loss: 0.1925368309020996\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33300: 0.234831765294075\n",
      "val loss: 0.18745508790016174\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33450: 0.20548859238624573\n",
      "val loss: 0.18665750324726105\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33600: 0.23977366089820862\n",
      "val loss: 0.18390178680419922\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33750: 0.24793367087841034\n",
      "val loss: 0.19614635407924652\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 33900: 0.2283402681350708\n",
      "val loss: 0.1966245472431183\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34050: 0.18939362466335297\n",
      "val loss: 0.1820143610239029\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34200: 0.1762494593858719\n",
      "val loss: 0.19035552442073822\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34350: 0.20843832194805145\n",
      "val loss: 0.18470540642738342\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34500: 0.24599431455135345\n",
      "val loss: 0.18389204144477844\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34650: 0.21420076489448547\n",
      "val loss: 0.19096268713474274\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34800: 0.2376203089952469\n",
      "val loss: 0.2027437388896942\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 34950: 0.22200937569141388\n",
      "val loss: 0.18890070915222168\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35100: 0.21315686404705048\n",
      "val loss: 0.18962761759757996\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35250: 0.1957906186580658\n",
      "val loss: 0.183921679854393\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35400: 0.21235685050487518\n",
      "val loss: 0.1824471652507782\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35550: 0.19764821231365204\n",
      "val loss: 0.1823738068342209\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35700: 0.2125176042318344\n",
      "val loss: 0.18692050874233246\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 35850: 0.19077065587043762\n",
      "val loss: 0.18509148061275482\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36000: 0.18340040743350983\n",
      "val loss: 0.1766745150089264\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36150: 0.17704065144062042\n",
      "val loss: 0.1790732741355896\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36300: 0.20700295269489288\n",
      "val loss: 0.1829547882080078\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36450: 0.22859954833984375\n",
      "val loss: 0.18262915313243866\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36600: 0.21051673591136932\n",
      "val loss: 0.1867360919713974\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36750: 0.28461721539497375\n",
      "val loss: 0.18951070308685303\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 36900: 0.22109003365039825\n",
      "val loss: 0.18208244442939758\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37050: 0.1884792298078537\n",
      "val loss: 0.1793249100446701\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37200: 0.18555976450443268\n",
      "val loss: 0.18058839440345764\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37350: 0.2010577768087387\n",
      "val loss: 0.18015813827514648\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37500: 0.20206034183502197\n",
      "val loss: 0.17862460017204285\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37650: 0.20557299256324768\n",
      "val loss: 0.2097642868757248\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37800: 0.19545216858386993\n",
      "val loss: 0.19520588219165802\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 37950: 0.2103850096464157\n",
      "val loss: 0.1929742693901062\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38100: 0.1697845607995987\n",
      "val loss: 0.19367176294326782\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38250: 0.1956620067358017\n",
      "val loss: 0.18407802283763885\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38400: 0.20324306190013885\n",
      "val loss: 0.18130196630954742\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38550: 0.19254957139492035\n",
      "val loss: 0.17867864668369293\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38700: 0.1862938404083252\n",
      "val loss: 0.1839524656534195\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 38850: 0.20927837491035461\n",
      "val loss: 0.18166688084602356\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39000: 0.1748770773410797\n",
      "val loss: 0.18216361105442047\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39150: 0.23454700410366058\n",
      "val loss: 0.17875079810619354\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39300: 0.18878433108329773\n",
      "val loss: 0.18017767369747162\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39450: 0.1918439269065857\n",
      "val loss: 0.18103860318660736\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39600: 0.19093838334083557\n",
      "val loss: 0.1810372918844223\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39750: 0.18984633684158325\n",
      "val loss: 0.18187542259693146\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 39900: 0.19000159204006195\n",
      "val loss: 0.18341603875160217\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40050: 0.20286667346954346\n",
      "val loss: 0.17890876531600952\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40200: 0.19741342961788177\n",
      "val loss: 0.1758183091878891\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40350: 0.21675586700439453\n",
      "val loss: 0.1884661465883255\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40500: 0.2210267037153244\n",
      "val loss: 0.1805521547794342\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40650: 0.20908533036708832\n",
      "val loss: 0.1823998987674713\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40800: 0.18814806640148163\n",
      "val loss: 0.18129342794418335\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 40950: 0.15356987714767456\n",
      "val loss: 0.18584640324115753\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41100: 0.1655701845884323\n",
      "val loss: 0.18104389309883118\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41250: 0.1836368888616562\n",
      "val loss: 0.18327979743480682\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41400: 0.1824638694524765\n",
      "val loss: 0.18482770025730133\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41550: 0.19363228976726532\n",
      "val loss: 0.18281742930412292\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41700: 0.16519975662231445\n",
      "val loss: 0.18108978867530823\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 41850: 0.1902492344379425\n",
      "val loss: 0.18647563457489014\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42000: 0.18649280071258545\n",
      "val loss: 0.18745142221450806\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42150: 0.18309472501277924\n",
      "val loss: 0.1824304610490799\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42300: 0.20135875046253204\n",
      "val loss: 0.1855313777923584\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42450: 0.17080190777778625\n",
      "val loss: 0.18092256784439087\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42600: 0.18743281066417694\n",
      "val loss: 0.18935535848140717\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42750: 0.17553387582302094\n",
      "val loss: 0.18764013051986694\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 42900: 0.1898180991411209\n",
      "val loss: 0.1907091587781906\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43050: 0.18832282721996307\n",
      "val loss: 0.18620283901691437\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43200: 0.18861083686351776\n",
      "val loss: 0.18453729152679443\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43350: 0.21196579933166504\n",
      "val loss: 0.18383246660232544\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43500: 0.20000974833965302\n",
      "val loss: 0.17906665802001953\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43650: 0.17815816402435303\n",
      "val loss: 0.1834997832775116\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43800: 0.20528605580329895\n",
      "val loss: 0.1869915872812271\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 43950: 0.17281413078308105\n",
      "val loss: 0.18234750628471375\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44100: 0.177061066031456\n",
      "val loss: 0.18613570928573608\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44250: 0.17110083997249603\n",
      "val loss: 0.18607938289642334\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44400: 0.17202892899513245\n",
      "val loss: 0.17475393414497375\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44550: 0.17342236638069153\n",
      "val loss: 0.18644104897975922\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44700: 0.17983612418174744\n",
      "val loss: 0.19412554800510406\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 44850: 0.20556239783763885\n",
      "val loss: 0.18717293441295624\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45000: 0.17888908088207245\n",
      "val loss: 0.18399475514888763\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45150: 0.1796349734067917\n",
      "val loss: 0.18273691833019257\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45300: 0.1665220558643341\n",
      "val loss: 0.18988749384880066\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45450: 0.19493012130260468\n",
      "val loss: 0.1943742334842682\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45600: 0.16617590188980103\n",
      "val loss: 0.1848890632390976\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45750: 0.2196313440799713\n",
      "val loss: 0.1865774691104889\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 45900: 0.1706259697675705\n",
      "val loss: 0.1830177754163742\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46050: 0.17683421075344086\n",
      "val loss: 0.18968284130096436\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46200: 0.18741559982299805\n",
      "val loss: 0.19213292002677917\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46350: 0.19332019984722137\n",
      "val loss: 0.19300174713134766\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46500: 0.19661729037761688\n",
      "val loss: 0.18245309591293335\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46650: 0.1851472109556198\n",
      "val loss: 0.18786104023456573\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46800: 0.18909497559070587\n",
      "val loss: 0.1878339946269989\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 46950: 0.20219318568706512\n",
      "val loss: 0.19051240384578705\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47100: 0.17309600114822388\n",
      "val loss: 0.19058287143707275\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47250: 0.1870584934949875\n",
      "val loss: 0.18660762906074524\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47400: 0.1746852695941925\n",
      "val loss: 0.19279572367668152\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47550: 0.20358362793922424\n",
      "val loss: 0.19124436378479004\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47700: 0.18388321995735168\n",
      "val loss: 0.19343987107276917\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 47850: 0.17340806126594543\n",
      "val loss: 0.18719524145126343\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48000: 0.17585448920726776\n",
      "val loss: 0.18737247586250305\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48150: 0.1921069473028183\n",
      "val loss: 0.18191245198249817\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48300: 0.17103330790996552\n",
      "val loss: 0.18536098301410675\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48450: 0.18260212242603302\n",
      "val loss: 0.17552714049816132\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48600: 0.17809902131557465\n",
      "val loss: 0.18103094398975372\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48750: 0.19193632900714874\n",
      "val loss: 0.18298599123954773\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 48900: 0.18543824553489685\n",
      "val loss: 0.1806638538837433\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49050: 0.1759251207113266\n",
      "val loss: 0.17941981554031372\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49200: 0.17276248335838318\n",
      "val loss: 0.18606220185756683\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49350: 0.18000055849552155\n",
      "val loss: 0.18578527867794037\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49500: 0.18131878972053528\n",
      "val loss: 0.18679319322109222\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49650: 0.1988525241613388\n",
      "val loss: 0.18945223093032837\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49800: 0.19397136569023132\n",
      "val loss: 0.1927357017993927\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 49950: 0.17049162089824677\n",
      "val loss: 0.19232609868049622\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50100: 0.18725435435771942\n",
      "val loss: 0.18245023488998413\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50250: 0.1855819672346115\n",
      "val loss: 0.1797168254852295\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50400: 0.19181019067764282\n",
      "val loss: 0.18876314163208008\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50550: 0.18826372921466827\n",
      "val loss: 0.18558931350708008\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50700: 0.16795672476291656\n",
      "val loss: 0.18855565786361694\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 50850: 0.18198351562023163\n",
      "val loss: 0.19579166173934937\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51000: 0.19385726749897003\n",
      "val loss: 0.19268293678760529\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51150: 0.21723996102809906\n",
      "val loss: 0.19195079803466797\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51300: 0.17988477647304535\n",
      "val loss: 0.19664108753204346\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51450: 0.18294525146484375\n",
      "val loss: 0.19346076250076294\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51600: 0.18440215289592743\n",
      "val loss: 0.19239763915538788\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51750: 0.1817140132188797\n",
      "val loss: 0.18784211575984955\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 51900: 0.18425224721431732\n",
      "val loss: 0.18339157104492188\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52050: 0.20870958268642426\n",
      "val loss: 0.186484232544899\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52200: 0.18622533977031708\n",
      "val loss: 0.1906460076570511\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52350: 0.17118999361991882\n",
      "val loss: 0.1913469433784485\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52500: 0.1866995394229889\n",
      "val loss: 0.1790100485086441\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52650: 0.17531289160251617\n",
      "val loss: 0.18287277221679688\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52800: 0.18381337821483612\n",
      "val loss: 0.1879866123199463\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 52950: 0.19448362290859222\n",
      "val loss: 0.19251471757888794\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53100: 0.19262909889221191\n",
      "val loss: 0.188829243183136\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53250: 0.19103744626045227\n",
      "val loss: 0.18449343740940094\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53400: 0.1815313696861267\n",
      "val loss: 0.18936344981193542\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53550: 0.187669575214386\n",
      "val loss: 0.19041138887405396\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53700: 0.17716175317764282\n",
      "val loss: 0.1925826072692871\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 53850: 0.1721411943435669\n",
      "val loss: 0.19276700913906097\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54000: 0.1777486354112625\n",
      "val loss: 0.19182974100112915\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54150: 0.17669086158275604\n",
      "val loss: 0.18943336606025696\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54300: 0.2047872543334961\n",
      "val loss: 0.18808090686798096\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54450: 0.19229422509670258\n",
      "val loss: 0.19186222553253174\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54600: 0.18426191806793213\n",
      "val loss: 0.1881922036409378\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54750: 0.17861787974834442\n",
      "val loss: 0.1934555321931839\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 54900: 0.18776623904705048\n",
      "val loss: 0.18733404576778412\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55050: 0.18560563027858734\n",
      "val loss: 0.19149215519428253\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55200: 0.16824336349964142\n",
      "val loss: 0.19165648519992828\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55350: 0.19042463600635529\n",
      "val loss: 0.18914982676506042\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55500: 0.20091834664344788\n",
      "val loss: 0.19708186388015747\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55650: 0.20111267268657684\n",
      "val loss: 0.18045508861541748\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55800: 0.1831602305173874\n",
      "val loss: 0.18016082048416138\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 55950: 0.16752466559410095\n",
      "val loss: 0.1800130009651184\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56100: 0.19634956121444702\n",
      "val loss: 0.18213412165641785\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56250: 0.1975228488445282\n",
      "val loss: 0.1843508630990982\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56400: 0.19915686547756195\n",
      "val loss: 0.18851181864738464\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56550: 0.20691180229187012\n",
      "val loss: 0.18630589544773102\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56700: 0.189900204539299\n",
      "val loss: 0.18199987709522247\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 56850: 0.17879946529865265\n",
      "val loss: 0.18425674736499786\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57000: 0.18522314727306366\n",
      "val loss: 0.17870858311653137\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57150: 0.18808957934379578\n",
      "val loss: 0.1835918426513672\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57300: 0.19829189777374268\n",
      "val loss: 0.18865135312080383\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57450: 0.20013092458248138\n",
      "val loss: 0.18772350251674652\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57600: 0.17899008095264435\n",
      "val loss: 0.19499368965625763\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57750: 0.18289057910442352\n",
      "val loss: 0.19159115850925446\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 57900: 0.21058142185211182\n",
      "val loss: 0.19688104093074799\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58050: 0.1816045045852661\n",
      "val loss: 0.19213904440402985\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58200: 0.19089172780513763\n",
      "val loss: 0.1789495348930359\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58350: 0.21095633506774902\n",
      "val loss: 0.1833876371383667\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58500: 0.19221507012844086\n",
      "val loss: 0.18668392300605774\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58650: 0.19325211644172668\n",
      "val loss: 0.18260721862316132\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58800: 0.19578789174556732\n",
      "val loss: 0.18417704105377197\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 58950: 0.18409916758537292\n",
      "val loss: 0.18117021024227142\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59100: 0.19091255962848663\n",
      "val loss: 0.18754155933856964\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59250: 0.1644698679447174\n",
      "val loss: 0.17993715405464172\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59400: 0.20710478723049164\n",
      "val loss: 0.18203571438789368\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59550: 0.1709161251783371\n",
      "val loss: 0.18033769726753235\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59700: 0.17715297639369965\n",
      "val loss: 0.18579454720020294\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 59850: 0.17912213504314423\n",
      "val loss: 0.18829086422920227\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60000: 0.2044363021850586\n",
      "val loss: 0.18253372609615326\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60150: 0.19077590107917786\n",
      "val loss: 0.19972506165504456\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60300: 0.18248870968818665\n",
      "val loss: 0.18915417790412903\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60450: 0.19039857387542725\n",
      "val loss: 0.19749322533607483\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60600: 0.18221619725227356\n",
      "val loss: 0.19191458821296692\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60750: 0.17230229079723358\n",
      "val loss: 0.19303415715694427\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 60900: 0.1726417988538742\n",
      "val loss: 0.19467133283615112\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61050: 0.19814454019069672\n",
      "val loss: 0.19085195660591125\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61200: 0.18715564906597137\n",
      "val loss: 0.1898895502090454\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61350: 0.22164101898670197\n",
      "val loss: 0.203003391623497\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61500: 0.1889508217573166\n",
      "val loss: 0.20469830930233002\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61650: 0.1745665818452835\n",
      "val loss: 0.20775234699249268\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61800: 0.19827882945537567\n",
      "val loss: 0.19195355474948883\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 61950: 0.17641036212444305\n",
      "val loss: 0.1920241266489029\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62100: 0.17907129228115082\n",
      "val loss: 0.1987433135509491\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62250: 0.1679047793149948\n",
      "val loss: 0.20765545964241028\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62400: 0.17774181067943573\n",
      "val loss: 0.21179886162281036\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62550: 0.1657336801290512\n",
      "val loss: 0.1971019059419632\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62700: 0.16144263744354248\n",
      "val loss: 0.19297273457050323\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 62850: 0.18404315412044525\n",
      "val loss: 0.18430443108081818\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63000: 0.18362121284008026\n",
      "val loss: 0.18681316077709198\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63150: 0.18428519368171692\n",
      "val loss: 0.18543028831481934\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63300: 0.23378944396972656\n",
      "val loss: 0.19195368885993958\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63450: 0.17259520292282104\n",
      "val loss: 0.1927727311849594\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63600: 0.18129658699035645\n",
      "val loss: 0.19143252074718475\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63750: 0.19778847694396973\n",
      "val loss: 0.18939608335494995\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 63900: 0.19622106850147247\n",
      "val loss: 0.18745221197605133\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64050: 0.1800166368484497\n",
      "val loss: 0.1879420280456543\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64200: 0.19230644404888153\n",
      "val loss: 0.1878669261932373\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64350: 0.20477278530597687\n",
      "val loss: 0.19634562730789185\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64500: 0.19561003148555756\n",
      "val loss: 0.19065432250499725\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64650: 0.204186350107193\n",
      "val loss: 0.1994602233171463\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64800: 0.17463071644306183\n",
      "val loss: 0.18963392078876495\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 64950: 0.2184918373823166\n",
      "val loss: 0.1949426233768463\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65100: 0.1842811554670334\n",
      "val loss: 0.18899360299110413\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65250: 0.20416764914989471\n",
      "val loss: 0.18608182668685913\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65400: 0.19582650065422058\n",
      "val loss: 0.18832702934741974\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65550: 0.20498251914978027\n",
      "val loss: 0.18737877905368805\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65700: 0.20451092720031738\n",
      "val loss: 0.1882951706647873\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 65850: 0.20279891788959503\n",
      "val loss: 0.18783676624298096\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66000: 0.187703475356102\n",
      "val loss: 0.1834695041179657\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66150: 0.20566760003566742\n",
      "val loss: 0.1860431283712387\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66300: 0.19352425634860992\n",
      "val loss: 0.18588054180145264\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66450: 0.19018511474132538\n",
      "val loss: 0.191306009888649\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66600: 0.19605384767055511\n",
      "val loss: 0.18681412935256958\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66750: 0.19285714626312256\n",
      "val loss: 0.18206842243671417\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 66900: 0.1892985999584198\n",
      "val loss: 0.18477188050746918\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67050: 0.1860322803258896\n",
      "val loss: 0.187686488032341\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67200: 0.18212449550628662\n",
      "val loss: 0.18405753374099731\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67350: 0.19169765710830688\n",
      "val loss: 0.19000986218452454\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67500: 0.20335058867931366\n",
      "val loss: 0.1839294135570526\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67650: 0.21505331993103027\n",
      "val loss: 0.17967969179153442\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67800: 0.1885181963443756\n",
      "val loss: 0.17616672813892365\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 67950: 0.199883371591568\n",
      "val loss: 0.18003717064857483\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68100: 0.2022043913602829\n",
      "val loss: 0.1837666779756546\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68250: 0.1961604803800583\n",
      "val loss: 0.18118521571159363\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68400: 0.20055241882801056\n",
      "val loss: 0.18007443845272064\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68550: 0.16899466514587402\n",
      "val loss: 0.17750872671604156\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68700: 0.17105458676815033\n",
      "val loss: 0.18065717816352844\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 68850: 0.18686030805110931\n",
      "val loss: 0.1831548511981964\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69000: 0.18311570584774017\n",
      "val loss: 0.17888998985290527\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69150: 0.17142699658870697\n",
      "val loss: 0.1857372522354126\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69300: 0.1787337064743042\n",
      "val loss: 0.18364456295967102\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69450: 0.18453483283519745\n",
      "val loss: 0.1874178647994995\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69600: 0.19012382626533508\n",
      "val loss: 0.18602782487869263\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69750: 0.19199435412883759\n",
      "val loss: 0.1828702837228775\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 69900: 0.17718105018138885\n",
      "val loss: 0.18237540125846863\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70050: 0.18262982368469238\n",
      "val loss: 0.17920827865600586\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70200: 0.19141316413879395\n",
      "val loss: 0.1839466094970703\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70350: 0.17648009955883026\n",
      "val loss: 0.18078544735908508\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70500: 0.18957620859146118\n",
      "val loss: 0.18416249752044678\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70650: 0.18419136106967926\n",
      "val loss: 0.17905671894550323\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70800: 0.17006921768188477\n",
      "val loss: 0.18374989926815033\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 70950: 0.1890602707862854\n",
      "val loss: 0.18206575512886047\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71100: 0.17512141168117523\n",
      "val loss: 0.17868772149085999\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71250: 0.18843893706798553\n",
      "val loss: 0.1819179654121399\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71400: 0.19745123386383057\n",
      "val loss: 0.18421097099781036\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71550: 0.16895125806331635\n",
      "val loss: 0.18261800706386566\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71700: 0.20240259170532227\n",
      "val loss: 0.19762131571769714\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 71850: 0.2532091438770294\n",
      "val loss: 0.19856828451156616\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72000: 0.18392537534236908\n",
      "val loss: 0.18790887296199799\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72150: 0.19653286039829254\n",
      "val loss: 0.1993747502565384\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72300: 0.180104598402977\n",
      "val loss: 0.19101180136203766\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72450: 0.19079802930355072\n",
      "val loss: 0.2002076506614685\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72600: 0.16744709014892578\n",
      "val loss: 0.19514015316963196\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72750: 0.20192961394786835\n",
      "val loss: 0.19442224502563477\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 72900: 0.18117134273052216\n",
      "val loss: 0.18963027000427246\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73050: 0.18767713010311127\n",
      "val loss: 0.19456718862056732\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73200: 0.18193355202674866\n",
      "val loss: 0.18988357484340668\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73350: 0.17004571855068207\n",
      "val loss: 0.1899711936712265\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73500: 0.20011095702648163\n",
      "val loss: 0.190043643116951\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73650: 0.19308705627918243\n",
      "val loss: 0.19339874386787415\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73800: 0.1660080999135971\n",
      "val loss: 0.1921244114637375\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 73950: 0.18189136683940887\n",
      "val loss: 0.19371721148490906\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74100: 0.1716458648443222\n",
      "val loss: 0.19069205224514008\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74250: 0.18818865716457367\n",
      "val loss: 0.18801568448543549\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74400: 0.17998890578746796\n",
      "val loss: 0.18950007855892181\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74550: 0.18935911357402802\n",
      "val loss: 0.18969988822937012\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74700: 0.20648625493049622\n",
      "val loss: 0.18956422805786133\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 74850: 0.19614262878894806\n",
      "val loss: 0.19023558497428894\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75000: 0.16854362189769745\n",
      "val loss: 0.19436576962471008\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75150: 0.18135248124599457\n",
      "val loss: 0.19370074570178986\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75300: 0.18664586544036865\n",
      "val loss: 0.1901274174451828\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75450: 0.18833868205547333\n",
      "val loss: 0.197076678276062\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75600: 0.17926840484142303\n",
      "val loss: 0.19576960802078247\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75750: 0.1749529391527176\n",
      "val loss: 0.19910433888435364\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 75900: 0.19371569156646729\n",
      "val loss: 0.19985297322273254\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76050: 0.17631343007087708\n",
      "val loss: 0.19400744140148163\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76200: 0.1856469064950943\n",
      "val loss: 0.1930914670228958\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76350: 0.20567099750041962\n",
      "val loss: 0.19978439807891846\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76500: 0.17968328297138214\n",
      "val loss: 0.20103605091571808\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76650: 0.18206873536109924\n",
      "val loss: 0.19220587611198425\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76800: 0.1815197914838791\n",
      "val loss: 0.19712775945663452\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 76950: 0.2087661772966385\n",
      "val loss: 0.1948537528514862\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77100: 0.1689036339521408\n",
      "val loss: 0.1914043128490448\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77250: 0.16800224781036377\n",
      "val loss: 0.18726664781570435\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77400: 0.17665351927280426\n",
      "val loss: 0.1954919844865799\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77550: 0.20532844960689545\n",
      "val loss: 0.19698522984981537\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77700: 0.16160182654857635\n",
      "val loss: 0.19259706139564514\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 77850: 0.1902836263179779\n",
      "val loss: 0.18811817467212677\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78000: 0.18288765847682953\n",
      "val loss: 0.1929471492767334\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78150: 0.20310045778751373\n",
      "val loss: 0.21128042042255402\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78300: 0.16321659088134766\n",
      "val loss: 0.1961125284433365\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78450: 0.18500131368637085\n",
      "val loss: 0.19230346381664276\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78600: 0.17334456741809845\n",
      "val loss: 0.1935373842716217\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78750: 0.18207979202270508\n",
      "val loss: 0.1902812123298645\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 78900: 0.1700267344713211\n",
      "val loss: 0.19268113374710083\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79050: 0.17516644299030304\n",
      "val loss: 0.19430023431777954\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79200: 0.16928227245807648\n",
      "val loss: 0.19234749674797058\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79350: 0.1936652958393097\n",
      "val loss: 0.18986080586910248\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79500: 0.18371836841106415\n",
      "val loss: 0.19380897283554077\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79650: 0.2054430991411209\n",
      "val loss: 0.19226911664009094\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79800: 0.1906711608171463\n",
      "val loss: 0.19182735681533813\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 79950: 0.1951902210712433\n",
      "val loss: 0.1920110285282135\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80100: 0.19626490771770477\n",
      "val loss: 0.18977434933185577\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80250: 0.17316941916942596\n",
      "val loss: 0.19314289093017578\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80400: 0.17882411181926727\n",
      "val loss: 0.1913854032754898\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80550: 0.17974267899990082\n",
      "val loss: 0.18158400058746338\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80700: 0.16669104993343353\n",
      "val loss: 0.18275971710681915\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 80850: 0.18169477581977844\n",
      "val loss: 0.18442896008491516\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81000: 0.17301343381404877\n",
      "val loss: 0.18460381031036377\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81150: 0.17276953160762787\n",
      "val loss: 0.18769767880439758\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81300: 0.19526462256908417\n",
      "val loss: 0.19830632209777832\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81450: 0.20370197296142578\n",
      "val loss: 0.19072742760181427\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81600: 0.18859310448169708\n",
      "val loss: 0.18707650899887085\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81750: 0.17101065814495087\n",
      "val loss: 0.18934011459350586\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 81900: 0.2128591388463974\n",
      "val loss: 0.19173462688922882\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82050: 0.18612699210643768\n",
      "val loss: 0.1839507669210434\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82200: 0.21444320678710938\n",
      "val loss: 0.18591991066932678\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82350: 0.1847873032093048\n",
      "val loss: 0.18513692915439606\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82500: 0.18588434159755707\n",
      "val loss: 0.1865638792514801\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82650: 0.1992482990026474\n",
      "val loss: 0.18675947189331055\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82800: 0.1924307644367218\n",
      "val loss: 0.18354317545890808\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 82950: 0.19487841427326202\n",
      "val loss: 0.19348616898059845\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83100: 0.17460936307907104\n",
      "val loss: 0.19129973649978638\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83250: 0.18854284286499023\n",
      "val loss: 0.19088195264339447\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83400: 0.17980805039405823\n",
      "val loss: 0.18472638726234436\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83550: 0.1814003735780716\n",
      "val loss: 0.19014117121696472\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83700: 0.24747657775878906\n",
      "val loss: 0.1831936240196228\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 83850: 0.20359189808368683\n",
      "val loss: 0.18934710323810577\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84000: 0.1621437817811966\n",
      "val loss: 0.18983522057533264\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84150: 0.20845186710357666\n",
      "val loss: 0.19201268255710602\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84300: 0.18947331607341766\n",
      "val loss: 0.1904963105916977\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84450: 0.1977018117904663\n",
      "val loss: 0.19063657522201538\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84600: 0.18542540073394775\n",
      "val loss: 0.1894843429327011\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84750: 0.19004645943641663\n",
      "val loss: 0.1880030333995819\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 84900: 0.16639772057533264\n",
      "val loss: 0.196909561753273\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85050: 0.1810108721256256\n",
      "val loss: 0.19714444875717163\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85200: 0.1802218109369278\n",
      "val loss: 0.19361849129199982\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85350: 0.18448176980018616\n",
      "val loss: 0.18672794103622437\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85500: 0.19558660686016083\n",
      "val loss: 0.19994252920150757\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85650: 0.1907215416431427\n",
      "val loss: 0.1919325441122055\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85800: 0.19794204831123352\n",
      "val loss: 0.19005201756954193\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 85950: 0.19115827977657318\n",
      "val loss: 0.19383379817008972\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86100: 0.1991652399301529\n",
      "val loss: 0.1894214004278183\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86250: 0.17435374855995178\n",
      "val loss: 0.19152043759822845\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86400: 0.195229634642601\n",
      "val loss: 0.19114619493484497\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86550: 0.2068338245153427\n",
      "val loss: 0.19383293390274048\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86700: 0.20025168359279633\n",
      "val loss: 0.18878459930419922\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 86850: 0.20052273571491241\n",
      "val loss: 0.18827874958515167\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87000: 0.20257063210010529\n",
      "val loss: 0.20044876635074615\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87150: 0.1873118132352829\n",
      "val loss: 0.1930384635925293\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87300: 0.18280313909053802\n",
      "val loss: 0.19567511975765228\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87450: 0.1903209537267685\n",
      "val loss: 0.18741463124752045\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87600: 0.18277166783809662\n",
      "val loss: 0.2022281438112259\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87750: 0.2034316062927246\n",
      "val loss: 0.20103195309638977\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 87900: 0.17671728134155273\n",
      "val loss: 0.1981189101934433\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88050: 0.2041378766298294\n",
      "val loss: 0.20261479914188385\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88200: 0.16052697598934174\n",
      "val loss: 0.19798687100410461\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88350: 0.17617741227149963\n",
      "val loss: 0.18910016119480133\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88500: 0.1932903379201889\n",
      "val loss: 0.1899380087852478\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88650: 0.18796634674072266\n",
      "val loss: 0.2074938267469406\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88800: 0.1977369636297226\n",
      "val loss: 0.20398852229118347\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 88950: 0.17240820825099945\n",
      "val loss: 0.1989080309867859\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89100: 0.17877095937728882\n",
      "val loss: 0.18640269339084625\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89250: 0.19228799641132355\n",
      "val loss: 0.1858966201543808\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89400: 0.17247655987739563\n",
      "val loss: 0.19951725006103516\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89550: 0.181336909532547\n",
      "val loss: 0.19552761316299438\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89700: 0.16602203249931335\n",
      "val loss: 0.19028547406196594\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 89850: 0.16798974573612213\n",
      "val loss: 0.19162872433662415\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90000: 0.21200929582118988\n",
      "val loss: 0.19745014607906342\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90150: 0.19360016286373138\n",
      "val loss: 0.1854289174079895\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90300: 0.18208836019039154\n",
      "val loss: 0.19371457397937775\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90450: 0.19266436994075775\n",
      "val loss: 0.2027093470096588\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90600: 0.1967460960149765\n",
      "val loss: 0.1859707534313202\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90750: 0.1839912384748459\n",
      "val loss: 0.194932222366333\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 90900: 0.1762101799249649\n",
      "val loss: 0.19017018377780914\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91050: 0.17192284762859344\n",
      "val loss: 0.18911078572273254\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91200: 0.18477436900138855\n",
      "val loss: 0.19859522581100464\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91350: 0.1876768171787262\n",
      "val loss: 0.19482892751693726\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91500: 0.1702396422624588\n",
      "val loss: 0.1984577775001526\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91650: 0.17964069545269012\n",
      "val loss: 0.19713683426380157\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91800: 0.19185729324817657\n",
      "val loss: 0.20259004831314087\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 91950: 0.17831319570541382\n",
      "val loss: 0.19671262800693512\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92100: 0.17691762745380402\n",
      "val loss: 0.19622312486171722\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92250: 0.18209697306156158\n",
      "val loss: 0.20895597338676453\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92400: 0.15699435770511627\n",
      "val loss: 0.20192524790763855\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92550: 0.1859760731458664\n",
      "val loss: 0.203578919172287\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92700: 0.17754271626472473\n",
      "val loss: 0.19141878187656403\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 92850: 0.17877641320228577\n",
      "val loss: 0.197707399725914\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93000: 0.18060865998268127\n",
      "val loss: 0.1966341882944107\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93150: 0.19892822206020355\n",
      "val loss: 0.1962280124425888\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93300: 0.21671143174171448\n",
      "val loss: 0.19368846714496613\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93450: 0.18681347370147705\n",
      "val loss: 0.193888321518898\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93600: 0.19221171736717224\n",
      "val loss: 0.19718259572982788\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93750: 0.18994459509849548\n",
      "val loss: 0.19691723585128784\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 93900: 0.17754562199115753\n",
      "val loss: 0.19793936610221863\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94050: 0.17723847925662994\n",
      "val loss: 0.19245317578315735\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94200: 0.18096207082271576\n",
      "val loss: 0.1863805055618286\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94350: 0.1874150037765503\n",
      "val loss: 0.19914737343788147\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94500: 0.18352149426937103\n",
      "val loss: 0.19372247159481049\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94650: 0.19435648620128632\n",
      "val loss: 0.20236626267433167\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94800: 0.20051483809947968\n",
      "val loss: 0.18739484250545502\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 94950: 0.1867789626121521\n",
      "val loss: 0.18959160149097443\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95100: 0.19705593585968018\n",
      "val loss: 0.18968577682971954\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95250: 0.2009163200855255\n",
      "val loss: 0.1890326738357544\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95400: 0.17821739614009857\n",
      "val loss: 0.18894201517105103\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95550: 0.1640452742576599\n",
      "val loss: 0.20261506736278534\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95700: 0.18444234132766724\n",
      "val loss: 0.17782841622829437\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 95850: 0.19543270766735077\n",
      "val loss: 0.19720159471035004\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96000: 0.190609410405159\n",
      "val loss: 0.18371310830116272\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96150: 0.18838687241077423\n",
      "val loss: 0.19365736842155457\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96300: 0.14782841503620148\n",
      "val loss: 0.19382180273532867\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96450: 0.18142130970954895\n",
      "val loss: 0.19627593457698822\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96600: 0.16883930563926697\n",
      "val loss: 0.18459589779376984\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96750: 0.16034181416034698\n",
      "val loss: 0.19226191937923431\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 96900: 0.2024092674255371\n",
      "val loss: 0.2016444355249405\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97050: 0.1759539395570755\n",
      "val loss: 0.1831388771533966\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97200: 0.1839417666196823\n",
      "val loss: 0.19044631719589233\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97350: 0.1678760051727295\n",
      "val loss: 0.19020278751850128\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97500: 0.2069803774356842\n",
      "val loss: 0.20940737426280975\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97650: 0.18361614644527435\n",
      "val loss: 0.18618746101856232\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97800: 0.1852058619260788\n",
      "val loss: 0.18888184428215027\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 97950: 0.17467091977596283\n",
      "val loss: 0.19067643582820892\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98100: 0.18735702335834503\n",
      "val loss: 0.2018396407365799\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98250: 0.18946753442287445\n",
      "val loss: 0.18628135323524475\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98400: 0.20663829147815704\n",
      "val loss: 0.19063922762870789\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98550: 0.18226976692676544\n",
      "val loss: 0.19153565168380737\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98700: 0.17832699418067932\n",
      "val loss: 0.1940755546092987\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 98850: 0.1794203817844391\n",
      "val loss: 0.19450417160987854\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99000: 0.18140845000743866\n",
      "val loss: 0.19298714399337769\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99150: 0.17628541588783264\n",
      "val loss: 0.1932605803012848\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99300: 0.1791282743215561\n",
      "val loss: 0.19534562528133392\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99450: 0.19940660893917084\n",
      "val loss: 0.19513778388500214\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99600: 0.18400846421718597\n",
      "val loss: 0.20765268802642822\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99750: 0.19762206077575684\n",
      "val loss: 0.19586896896362305\n",
      "\n",
      "\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "overall_steps 99900: 0.1831301897764206\n",
      "val loss: 0.1916683167219162\n",
      "\n",
      "\n",
      "*****************************************************************************************************Complete training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13697326183319092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter1d, gaussian_filter1d\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "# Post-processing functions\n",
    "def moving_average(data, window_size, axis=0):\n",
    "    return uniform_filter1d(data, size=window_size, axis=axis, mode='reflect')\n",
    "\n",
    "def savitzky_golay_filter(data, window_size, poly_order, axis=0):\n",
    "    return savgol_filter(data, window_size, poly_order, axis=axis)\n",
    "\n",
    "def gaussian_smoothing(data, sigma, axis=0):\n",
    "    return gaussian_filter1d(data, sigma, axis=axis)\n",
    "\n",
    "def example_post_process(data):\n",
    "    return moving_average(data, window_size=10,axis=-1) #window_size=3-15\n",
    "    # return savitzky_golay_filter(data, window_size=5, poly_order=2) #window_size=3-15, poly_order=2-5\n",
    "    # return gaussian_smoothing(data, sigma=1) #sigma=0.1-2\n",
    "\n",
    "\n",
    "run_train_model(model, (train_dataset, test_dataset), train_config, device, post_process=example_post_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
